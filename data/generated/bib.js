define({ entries : {
    "Aldughayfiq2023Explainable": {
        "abstract": "This paper applies explainable-AI techniques (LIME and SHAP) to deep-learning models for retinoblastoma diagnosis, providing interpretable visual explanations that can support clinical trust.",
        "author": "Buthaina Aldughayfiq and Faisal Ashfaq and Nadeem Z. Jhanjhi and Mamoona Humayun",
        "doi": "10.3390/diagnostics13111932",
        "journal": "Diagnostics",
        "keywords": "type:medical-ai, retinoblastoma, explainability, LIME, SHAP",
        "number": "11",
        "pages": "1932",
        "title": "Explainable AI for Retinoblastoma Diagnosis: Interpreting Deep Learning Models with LIME and SHAP",
        "type": "article",
        "url": "https://www.mdpi.com/2075-4418/13/11/1932",
        "volume": "13",
        "year": "2023"
    },
    "Alicioglu2022Survey": {
        "abstract": "This survey reviews visual\u2010analytics techniques that make machine-learning models more interpretable, summarising design patterns, evaluation strategies, and open challenges in the field of Explainable Artificial Intelligence.",
        "author": "Gokce Alicioglu and Baozhong Sun",
        "doi": "10.1016/j.cag.2021.09.002",
        "journal": "Computers \\& Graphics",
        "keywords": "type:survey, visual-analytics, explainable-ai",
        "pages": "202--215",
        "title": "A Survey of Visual Analytics for Explainable Artificial Intelligence Methods",
        "type": "article",
        "url": "https://doi.org/10.1016/j.cag.2021.09.002",
        "volume": "103",
        "year": "2022"
    },
    "Hohman2019Visual": {
        "abstract": "This interrogative survey maps current visual\u2010analytics techniques for deep\u2010learning models, highlights unsolved challenges, and outlines future research directions at the intersection of visualization and AI interpretability.",
        "author": "Fred Hohman and Michael Kahng and Rich Pienta and Duen Horng Chau",
        "doi": "10.1109/TVCG.2018.2843369",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "keywords": "type:survey, visual-analytics, deep-learning, explainable-ai",
        "number": "8",
        "pages": "2674--2693",
        "title": "Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers",
        "type": "article",
        "url": "https://doi.org/10.1109/TVCG.2018.2843369",
        "volume": "25",
        "year": "2019"
    },
    "LaRosa2023State": {
        "abstract": "This state\u2010of\u2010the\u2010art report surveys visual\u2010analytics approaches that enhance the explainability of deep\u2010learning models, summarising current techniques, application domains, and open research challenges.",
        "author": "Marco La Rosa and Kostiantyn Kucher and Anders Kerren",
        "doi": "10.1111/cgf.14733",
        "journal": "Computer Graphics Forum",
        "keywords": "type:survey, visual-analytics, deep-learning, explainable-ai",
        "number": "1",
        "pages": "1--25",
        "title": "State of the Art of Visual Analytics for Explainable Deep Learning",
        "type": "article",
        "url": "https://doi.org/10.1111/cgf.14733",
        "volume": "42",
        "year": "2023"
    },
    "Lundberg2020Local2Global": {
        "abstract": "The paper introduces a unified framework that aggregates local SHAP explanations into global feature\u2010importance measures, enabling comprehensive understanding of tree\u2010based machine\u2010learning models across large datasets and application domains.",
        "author": "Scott M. Lundberg and Gabriel Erion and Hans Chen and Andrew DeGrave and Jason M. Prutkin and Bryce Nair and others",
        "doi": "10.1038/s42256-019-0138-9",
        "journal": "Nature Machine Intelligence",
        "keywords": "type:method, SHAP, explainable-ai, tree-models",
        "number": "1",
        "pages": "56--67",
        "title": "From Local Explanations to Global Understanding with Explainable AI for Trees",
        "type": "article",
        "url": "https://doi.org/10.1038/s42256-019-0138-9",
        "volume": "2",
        "year": "2020"
    },
    "Mi2020Review": {
        "abstract": "This paper surveys interpretation techniques in machine learning, organising them by model type and discussing their strengths, limitations and future research challenges, with the aim of advancing interpretable ML.",
        "author": "Jian{-}Xun Mi and An{-}Di Li and Li{-}Fang Zhou",
        "doi": "10.1109/ACCESS.2020.3032756",
        "journal": "IEEE Access",
        "keywords": "type:survey, interpretable-ML, explainable-ai",
        "pages": "191969--191985",
        "title": "Review Study of Interpretation Methods for Future Interpretable Machine Learning",
        "type": "article",
        "url": "https://doi.org/10.1109/ACCESS.2020.3032756",
        "volume": "8",
        "year": "2020"
    },
    "Rudin2022Interpretable": {
        "abstract": "This comprehensive survey distills the core principles that underpin interpretable machine-learning models and outlines ten open research challenges\u2014from evaluation standards to human-centered design\u2014that must be tackled for widespread, responsible adoption of transparent AI systems.",
        "author": "Cynthia Rudin and Caroline Chen and Zehong Chen and Hao Huang and Larissa Semenova and Chaofan Zhong",
        "doi": "10.1214/21-SS133",
        "journal": "Statistical Surveys",
        "keywords": "type:survey, interpretable-ML, explainable-ai, grand-challenges",
        "pages": "1--85",
        "title": "Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges",
        "type": "article",
        "url": "https://doi.org/10.1214/21-SS133",
        "volume": "16",
        "year": "2022"
    },
    "Sokol2019Counterfactual": {
        "abstract": "The paper investigates counterfactual explanations as a means to enhance the safety and transparency of machine-learning systems, discussing their potential benefits, limitations, and open research challenges.",
        "author": "Kacper Sokol and Peter A. Flach",
        "booktitle": "Proceedings of the {AAAI} Workshop on Artificial Intelligence Safety (SafeAI 2019)",
        "keywords": "type:method, counterfactual, explainable-ai, AI-safety",
        "pages": "13--19",
        "title": "Counterfactual Explanations of Machine Learning Predictions: Opportunities and Challenges for {AI} Safety",
        "type": "inproceedings",
        "url": "https://dblp.org/rec/conf/aaai/SokolF19",
        "year": "2019"
    },
    "Verma2020Counterfactual": {
        "abstract": "This survey synthesises research on counterfactual explanations and algorithmic recourse, comparing generation strategies, evaluation metrics, and open challenges in deploying actionable explainability for machine-learning systems.",
        "archiveprefix": "arXiv",
        "author": "Sahil Verma and Vasu Boonsanong and Minh Hoang and Kevin E. Hines and John P. Dickerson and Chirag Shah",
        "eprint": "2010.10596",
        "howpublished": "arXiv preprint",
        "keywords": "type:survey, counterfactual, algorithmic-recourse, explainable-ai",
        "title": "Counterfactual Explanations and Algorithmic Recourses for Machine Learning: A Review",
        "type": "misc",
        "url": "https://doi.org/10.48550/arXiv.2010.10596",
        "year": "2020"
    },
    "Zhang2021Musical": {
        "abstract": "This study shows that prior musical experience mitigates age-related declines in speech-in-noise comprehension. The benefit is independent of the specific type of musical training and is strongly mediated by working-memory capacity.",
        "author": "Li Zhang and Xiaoya Fu and Dongdong Luo and Lingling Xing and Yan Du",
        "doi": "10.1097/AUD.0000000000000921",
        "journal": "Ear and Hearing",
        "keywords": "type:empirical, musical-training, aging, speech-in-noise, working-memory",
        "number": "4",
        "pages": "1010--1020",
        "title": "Musical Experience Offsets Age-Related Decline in Understanding Speech-in-Noise: Type of Training Does Not Matter, Working Memory Is the Key",
        "type": "article",
        "url": "https://doi.org/10.1097/AUD.0000000000000921",
        "volume": "42",
        "year": "2021"
    }
}});